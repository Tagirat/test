{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97926,"databundleVersionId":11667523,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom urllib.parse import urlparse\nfrom collections import defaultdict\nimport math\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:49:44.318887Z","iopub.execute_input":"2025-04-08T21:49:44.319285Z","iopub.status.idle":"2025-04-08T21:49:44.323724Z","shell.execute_reply.started":"2025-04-08T21:49:44.319228Z","shell.execute_reply":"2025-04-08T21:49:44.322650Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Параметры","metadata":{}},{"cell_type":"code","source":"MAX_FEATURES = 1500\nNGRAM_RANGE = (1, 2)\nMAX_ITER = 500\nSAMPLE_SIZE = 30000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:49:49.091048Z","iopub.execute_input":"2025-04-08T21:49:49.091390Z","iopub.status.idle":"2025-04-08T21:49:49.095343Z","shell.execute_reply.started":"2025-04-08T21:49:49.091361Z","shell.execute_reply":"2025-04-08T21:49:49.094343Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## TF-IDF","metadata":{}},{"cell_type":"code","source":"class tf_idf:\n    def __init__(self, max_features=MAX_FEATURES, ngram_range=NGRAM_RANGE):\n        self.max_features = max_features\n        self.ngram_range = ngram_range\n        self.vocab = {}\n        self.idf = {}\n    \n    def get_ngrams(self, text):\n        words = re.findall(r'\\w{3,}', text.lower())\n        ngrams = []\n        for n in range(self.ngram_range[0], min(self.ngram_range[1], 2) + 1):\n            ngrams.extend([' '.join(words[i:i+n]) for i in range(len(words)-n+1)])\n        return ngrams\n    \n    def fit(self, texts):\n        doc_count = len(texts)\n        term_doc_freq = defaultdict(int)\n        term_freq = defaultdict(int)\n        \n        for text in tqdm(texts[:SAMPLE_SIZE], desc=\"Building vocabulary\"):\n            ngrams = self.get_ngrams(text)\n            seen = set()\n            for gram in ngrams:\n                term_freq[gram] += 1\n                if gram not in seen:\n                    term_doc_freq[gram] += 1\n                    seen.add(gram)\n                    top_terms = sorted(term_freq.items(), key=lambda x: -x[1])[:self.max_features]\n        self.vocab = {term: idx for idx, (term, _) in enumerate(top_terms)}\n        \n        for term in self.vocab:\n            self.idf[term] = math.log((doc_count + 1) / (term_doc_freq[term] + 1)) + 1\n    \n    def transform(self, texts):\n        rows = np.zeros((len(texts), len(self.vocab)), dtype=np.float32)\n        \n        for i, text in enumerate(tqdm(texts, desc=\"Vectorizing\")):\n            ngrams = self.get_ngrams(text)\n            for gram in ngrams:\n                if gram in self.vocab:\n                    rows[i, self.vocab[gram]] += 1\n        \n        return rows * np.array(list(self.idf.values()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:49:52.007867Z","iopub.execute_input":"2025-04-08T21:49:52.008196Z","iopub.status.idle":"2025-04-08T21:49:52.016934Z","shell.execute_reply.started":"2025-04-08T21:49:52.008166Z","shell.execute_reply":"2025-04-08T21:49:52.015858Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Логистическая регрессия","metadata":{}},{"cell_type":"code","source":"class Logistic_regression:\n    def __init__(self, learning_rate=0.1, n_iter=MAX_ITER):\n        self.lr = learning_rate\n        self.n_iter = n_iter\n    \n    def sigmoid(self, z):\n        return 1 / (1 + np.exp(-np.clip(z, -20, 20)))\n    \n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features, dtype=np.float32)\n        self.bias = 0\n        \n        pos_weight = np.sum(y == 0) / np.sum(y == 1)\n        indices = np.arange(n_samples)\n        batch_size = min(1000, n_samples)\n        \n        for _ in tqdm(range(self.n_iter), desc=\"Training\"):\n            np.random.shuffle(indices)\n            for i in range(0, n_samples, batch_size):\n                batch_idx = indices[i:i+batch_size]\n                X_batch = X[batch_idx]\n                y_batch = y[batch_idx]\n                \n                linear = np.dot(X_batch, self.weights) + self.bias\n                preds = self.sigmoid(linear)\n                error = preds - y_batch\n                \n                grad_w = np.dot(X_batch.T, error * np.where(y_batch == 1, pos_weight, 1)) / len(batch_idx)\n                grad_b = np.sum(error * np.where(y_batch == 1, pos_weight, 1)) / len(batch_idx)\n                \n                self.weights -= self.lr * grad_w\n                self.bias -= self.lr * grad_b\n    \n    def predict(self, X, threshold=0.5):\n        return (self.sigmoid(np.dot(X, self.weights) + self.bias) >= threshold).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:49:55.718594Z","iopub.execute_input":"2025-04-08T21:49:55.718897Z","iopub.status.idle":"2025-04-08T21:49:55.726488Z","shell.execute_reply.started":"2025-04-08T21:49:55.718872Z","shell.execute_reply":"2025-04-08T21:49:55.725364Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Функции предобработки","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]|\\d|_', ' ', text)\n    return ' '.join(text.split())\n\ndef extract_url_features(url):\n    try:\n        parsed = urlparse(url)\n        domain = parsed.netloc\n        return {\n            'url_len': min(len(url), 300),\n            'domain_len': len(domain),\n            'num_dots': domain.count('.'),\n            'is_https': int(parsed.scheme == 'https'),\n            'has_adult': int(any(kw in url.lower() for kw in ['porn', 'sex', 'xxx', 'adult']))\n        }\n    except:\n        return {'url_len': 0, 'domain_len': 0, 'num_dots': 0, 'is_https': 0, 'has_adult': 0}\n\ndef calculate_f1(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    return f1, precision, recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:49:58.151926Z","iopub.execute_input":"2025-04-08T21:49:58.152224Z","iopub.status.idle":"2025-04-08T21:49:58.159122Z","shell.execute_reply.started":"2025-04-08T21:49:58.152199Z","shell.execute_reply":"2025-04-08T21:49:58.158129Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def run_pipeline():\n    # Загрузка данных\n    try:\n        train = pd.read_csv('/kaggle/input/ml-2025-spring-porn-detection/train.csv', nrows=SAMPLE_SIZE)\n        test = pd.read_csv('/kaggle/input/ml-2025-spring-porn-detection/test.csv')\n    except:\n        train = pd.read_csv('train.csv', nrows=SAMPLE_SIZE)\n        test = pd.read_csv('test.csv')\n    \n    # Балансировка классов\n    pos = train[train['label'] == 1]\n    neg = train[train['label'] == 0].sample(min(len(pos)*2, len(pos)+50000), random_state=42)\n    train = pd.concat([pos, neg]).sample(frac=1, random_state=42)\n    \n    # Разделение данных\n    split_idx = int(0.9 * len(train))\n    train_df = train.iloc[:split_idx]\n    val_df = train.iloc[split_idx:]\n    \n    # Предобработка\n    print(\"Preprocessing...\")\n    for df in [train_df, val_df, test]:\n        df['clean_title'] = df['title'].apply(preprocess_text)\n    \n    # Извлечение признаков\n    print(\"Extracting URL features...\")\n    url_train = np.array([list(extract_url_features(url).values()) for url in tqdm(train_df['url'])], dtype=np.float32)\n    url_val = np.array([list(extract_url_features(url).values()) for url in tqdm(val_df['url'])], dtype=np.float32)\n    url_test = np.array([list(extract_url_features(url).values()) for url in tqdm(test['url'])], dtype=np.float32)\n    \n    # Векторизация текста\n    print(\"Vectorizing text...\")\n    vectorizer = tf_idf()\n    vectorizer.fit(train_df['clean_title'])\n    X_text_train = vectorizer.transform(train_df['clean_title'])\n    X_text_val = vectorizer.transform(val_df['clean_title'])\n    X_text_test = vectorizer.transform(test['clean_title'])\n    \n    # Объединение признаков\n    X_train = np.hstack([url_train, X_text_train])\n    X_val = np.hstack([url_val, X_text_val])\n    y_train = train_df['label'].values\n    y_val = val_df['label'].values\n    X_test = np.hstack([url_test, X_text_test])\n    # Обучение модели\n    print(\"Training model...\")\n    model = Logistic_regression()\n    model.fit(X_train, y_train)\n    \n    # Подбор порога\n    print(\"Finding best threshold...\")\n    thresholds = np.linspace(0.3, 0.7, 11)\n    best_thresh = 0.5\n    best_f1 = 0\n    \n    for thresh in thresholds:\n        preds = (model.sigmoid(np.dot(X_val, model.weights) + model.bias) >= thresh).astype(int)\n        f1, _, _ = calculate_f1(y_val, preds)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_thresh = thresh\n    \n    # Оценка\n    val_preds = (model.sigmoid(np.dot(X_val, model.weights) + model.bias)) >= best_thresh\n    f1, prec, rec = calculate_f1(y_val, val_preds)\n    \n    print(f\"\\nBest F1: {best_f1:.4f} at threshold {best_thresh:.2f}\")\n    print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}\")\n    \n    # Предсказание\n    test_preds = (model.sigmoid(np.dot(X_test, model.weights) + model.bias) >= best_thresh).astype(int)\n    submission = pd.DataFrame({'ID': test['ID'], 'label': test_preds})\n    submission.to_csv('submission.csv', index=False)\n    print(\"\\nSubmission saved!\")\n    \nif __name__ == \"__main__\":\n    run_pipeline()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:50:01.594039Z","iopub.execute_input":"2025-04-08T21:50:01.594398Z","iopub.status.idle":"2025-04-08T22:11:42.670366Z","shell.execute_reply.started":"2025-04-08T21:50:01.594368Z","shell.execute_reply":"2025-04-08T22:11:42.669129Z"}},"outputs":[{"name":"stdout","text":"Preprocessing...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-21-1bfbf0a3ad45>:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['clean_title'] = df['title'].apply(preprocess_text)\n<ipython-input-21-1bfbf0a3ad45>:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['clean_title'] = df['title'].apply(preprocess_text)\n","output_type":"stream"},{"name":"stdout","text":"Extracting URL features...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10003 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42945ef7a8f14152b4105dcc1842729a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1112 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65aa5b21ffc40a2959fe6e05f7448ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165378 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbac7a513824454c8c156b9f762369d4"}},"metadata":{}},{"name":"stdout","text":"Vectorizing text...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Building vocabulary:   0%|          | 0/10003 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eabf8defd6164774a329c56c88f3a03b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Vectorizing:   0%|          | 0/10003 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01bb6fc5e2924f12bdf7494bd4b4fd3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Vectorizing:   0%|          | 0/1112 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25fe5ccddc7f4ac4ac786c4b75f8bd96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Vectorizing:   0%|          | 0/165378 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6120df6c0f14dfc8b74f0071a3d1577"}},"metadata":{}},{"name":"stdout","text":"Training model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f6bcb99e374fb6ba657dd7266e8bb5"}},"metadata":{}},{"name":"stdout","text":"Finding best threshold...\n\nBest F1: 0.9617 at threshold 0.50\nPrecision: 0.9686, Recall: 0.9549\n\nSubmission saved!\n","output_type":"stream"}],"execution_count":21}]}